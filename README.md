Spark Failover POC avec Docker Compose
Un proof of concept (POC) dÃ©montrant la gestion du failover automatique avec Apache Spark dans un environnement Docker Compose.
Structure du projet
spark-failover-poc/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Dockerfile.monitor
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ failover_job.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ monitor/
â”‚   â”œâ”€â”€ monitor.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”œâ”€â”€ output/
â”‚   â””â”€â”€ checkpoints/
â””â”€â”€ logs/
Fichiers de configuration
requirements.txt
pyspark==3.5.0
pandas==2.0.3
requests==2.31.0
flask==2.3.2
watchdog==3.0.0
.env
bashSPARK_MASTER_URL=spark://spark-master:7077
SPARK_WORKER_MEMORY=1G
SPARK_WORKER_CORES=2
COMPOSE_PROJECT_NAME=spark-failover-poc
.gitignore
gitignore# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Jupyter Notebook
.ipynb_checkpoints

# Environment
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Docker
.dockerignore

# Spark
logs/
data/input/
data/output/
data/checkpoints/
*.log
metastore_db/
derby.log
spark-warehouse/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db
Makefile
makefile.PHONY: build up down logs clean restart status

# Variables
COMPOSE_FILE = docker-compose.yml
PROJECT_NAME = spark-failover-poc

# Construire et dÃ©marrer
build:
	docker-compose -f $(COMPOSE_FILE) build

up:
	docker-compose -f $(COMPOSE_FILE) up -d

# DÃ©marrer avec logs
up-logs:
	docker-compose -f $(COMPOSE_FILE) up

# ArrÃªter
down:
	docker-compose -f $(COMPOSE_FILE) down

# Voir les logs
logs:
	docker-compose -f $(COMPOSE_FILE) logs -f

# Logs d'un service spÃ©cifique
logs-app:
	docker-compose -f $(COMPOSE_FILE) logs -f spark-app

logs-master:
	docker-compose -f $(COMPOSE_FILE) logs -f spark-master

logs-worker:
	docker-compose -f $(COMPOSE_FILE) logs -f spark-worker

logs-monitor:
	docker-compose -f $(COMPOSE_FILE) logs -f monitor

# Statut des services
status:
	docker-compose -f $(COMPOSE_FILE) ps

# RedÃ©marrer un service
restart-app:
	docker-compose -f $(COMPOSE_FILE) restart spark-app

restart-all:
	docker-compose -f $(COMPOSE_FILE) restart

# Nettoyer
clean:
	docker-compose -f $(COMPOSE_FILE) down -v
	docker system prune -f
	sudo rm -rf data/input/* data/output/* logs/*

# Ouvrir une session dans le conteneur
shell-app:
	docker-compose -f $(COMPOSE_FILE) exec spark-app bash

shell-master:
	docker-compose -f $(COMPOSE_FILE) exec spark-master bash

# Tester la connectivitÃ©
test:
	curl -f http://localhost:8080 && echo "âœ“ Spark Master OK"
	curl -f http://localhost:8081 && echo "âœ“ Spark Worker OK"
	curl -f http://localhost:3000 && echo "âœ“ Monitor OK"

# DÃ©veloppement
dev-build:
	docker-compose -f $(COMPOSE_FILE) build --no-cache

dev-up:
	docker-compose -f $(COMPOSE_FILE) up --build

# Monitoring
monitor:
	@echo "ðŸ“Š Interfaces disponibles:"
	@echo "Spark Master UI: http://localhost:8080"
	@echo "Spark Worker UI: http://localhost:8081"
	@echo "Monitor Dashboard: http://localhost:3000"
	@echo "API Status: http://localhost:3000/api/status"
Installation et utilisation
1. Cloner et configurer
bashgit clone <your-repo>
cd spark-failover-poc
cp .env.example .env  # Ajuster les variables si nÃ©cessaire
2. DÃ©marrer le POC
bash# MÃ©thode 1: Avec Makefile
make build
make up

# MÃ©thode 2: Docker Compose direct
docker-compose up -d --build
3. AccÃ©der aux interfaces

Spark Master UI: http://localhost:8080
Spark Worker UI: http://localhost:8081
Monitor Dashboard: http://localhost:3000
API Status: http://localhost:3000/api/status

4. Surveiller les logs
bash# Tous les logs
make logs

# Logs spÃ©cifiques
make logs-app
make logs-master
make logs-monitor
5. Tester le failover
bash# Forcer un redÃ©marrage de l'application
make restart-app

# Voir le statut
make status

# Tester la connectivitÃ©
make test
FonctionnalitÃ©s du POC
âœ… Failover automatique

RedÃ©marrage automatique en cas de panne
Backoff exponentiel entre les tentatives
Limite du nombre de redÃ©marrages

âœ… Monitoring en temps rÃ©el

Interface web avec dashboard
API REST pour intÃ©gration
Surveillance des logs
MÃ©triques des ressources

âœ… Configuration Docker

Services isolÃ©s
RÃ©seaux Docker
Volumes persistants
Health checks

âœ… Simulation de pannes

Pannes alÃ©atoires (30% de chance)
Gestion des exceptions
Nettoyage automatique des ressources

Personnalisation
Modifier le taux de panne
Dans apps/failover_job.py:
pythonself.failure_rate = 0.5  # 50% de chance de panne
Ajuster les ressources
Dans docker-compose.yml:
yamlenvironment:
  - SPARK_WORKER_MEMORY=2G
  - SPARK_WORKER_CORES=2
Modifier la frÃ©quence de traitement
Dans apps/failover_job.py:
pythontime.sleep(60)  # Attendre 60 secondes entre les cycles
DÃ©pannage
Logs dÃ©taillÃ©s
bashdocker-compose logs -f --tail=100 spark-app
RedÃ©marrage complet
bashmake clean
make build
make up
VÃ©rifier les ports
bashnetstat -tlnp | grep -E "8080|8081|3000"
Production
Pour un usage en production, considÃ©rez:

Utiliser un registry Docker privÃ©
Configurer des secrets pour les credentials
Ajouter des ressources limits/requests
Mettre en place un monitoring externe (Prometheus/Grafana)
Utiliser un orchestrateur (Kubernetes)

Commandes utiles
CommandeDescriptionmake buildConstruire les images Dockermake upDÃ©marrer tous les servicesmake downArrÃªter tous les servicesmake logsVoir tous les logsmake statusVoir le statut des servicesmake cleanNettoyer complÃ¨tementmake testTester la connectivitÃ©make monitorAfficher les URLs des interfaces
